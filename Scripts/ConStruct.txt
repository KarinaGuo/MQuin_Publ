# Thin parent + convert to numeric
cp "/home/karina/mqgwas/parent_iter_2/data/catvcf/Mq_filtmiss_cat.vcf.gz" .
/usr/bin/vcftools --gzvcf "Mq_filtmiss_cat.vcf.gz" --thin 15000 --recode --recode-INFO-all --stdout | gzip -c > Mq_vcf_thinnedSNPs.vcf.gz
# After filtering, kept 16532 out of a possible 47731087 Sites


/usr/bin/vcftools --gzvcf "/home/karina/Mq_vcf_thinnedSNPs.vcf.gz" --012 --out Mq_vcf_thinnedSNPs_numeric
#rm /home/karina/Mq_filtmiss_cat.vcf.gz
#rm "/home/karina/Mq_vcf_thinnedSNPs.vcf.gz"
#rm *.012*

# Run data_setup.R to create the cs file (numeric DArT genotype & metadata file) - ensure that rownames(gt_filt) and data$meta$sample_names are in the same order

# Create conda environment
conda create -n conStruct  r-essentials r-base
conda activate conStruct
conda install -c conda-forge 
R
install.packages("conStruct", repo = "https://cran.csiro.au/", dependencies = TRUE)
library(conStruct)
load("/home/karina/mqgwas/conStruct/data/MelaleucaQuinquenervia_NA.rda")


#######################################################################################################
## Iter_4 - rerunning without techreps pre-set Pops and with qld samples; 60k SNPs & n.iter=10000, n.chains=2 #  Datasetup locally in R using data_setup R under subheading: #################################### Set 4

# thin vcf to 60k

/usr/bin/vcftools --gzvcf "/home/karina/mqgwas/parent_iter_2/data/catvcf/Mq_filtmiss_cat.vcf.gz" --keep "/recer1/karina/parents/iter_2/data/meta/out_library_list_30042025.txt" --maf 0.05 --thin 4000 --max-missing 0.5 --recode --recode-INFO-all --out /home/karina/mqgwas/parent_iter_2/PCA_3/Mq_60kthin.vcf

# convert to numeric

/usr/bin/vcftools --vcf /home/karina/mqgwas/parent_iter_2/PCA_3/Mq_60kthin.vcf.recode.vcf --012 --out /home/karina/mqgwas/parent_iter_2/construct_iter4/Mq_60kthin_numeric

Run datasetup.R under Set 4. to create the cs file (numeric DArT genotype & metadata file) - ensure that rownames(gt_filt) and data$meta$sample_names are in the same order

mkdir conStruct_output
mkdir data
# Put files into here





conda activate conStruct
R
library(conStruct)
load("data/MelaleucaQuinquenervia_NA.rda")

# multiple runs loop with spatial distance
for (k in 1:6){
   print (paste("running", k))
   con <- conStruct(spatial= TRUE, K=k, freqs = cs$freq, geoDist = cs$dist, coords = cs$lon_lat, prefix = paste0("conStruct_output/",cs$prefix,"_TRUE_K",k), n.iter=10000, n.chains=2)
}


26: The largest R-hat is 1.86, indicating chains have not mixed.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#r-hat
27: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess
28: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess

# Loop through output files generated by conStruct and calculate/plot layer contributions.

lc.calculations <- function (geo, num_runs){
  nm = num_runs
  nma = nm-1
  # Build data format
  K=1
  # load the conStruct.results.Robj and data.block.Robj from files saved at the end of a conStruct run
  layer.contributions <- matrix(NA,nrow=nm,ncol=nm)
  load(paste0("conStruct_output/",cs$prefix,"_",geo,"_K",K,"_conStruct.results.Robj"))
  load(paste0("conStruct_output/",cs$prefix,"_",geo,"_K",K,"_data.block.Robj"))
  # calculate layer contributions
  layer.contributions[,1] <- c(calculate.layer.contribution(conStruct.results[[1]],data.block),rep(0,nma))
  tmp <- conStruct.results[[1]]$MAP$admix.proportions
  
  # Loop thorugh other runs
  for (k in 2:nm){
    load(paste0("conStruct_output/",cs$prefix,"_",geo,"_K",k,"_conStruct.results.Robj"))
    load(paste0("conStruct_output/",cs$prefix,"_",geo,"_K",k,"_data.block.Robj"))
    # match layers up across runs to keep plotting colors consistent
    tmp.order <- match.layers.x.runs(tmp,conStruct.results[[1]]$MAP$admix.proportions)
    # calculate layer contributions
    layer.contributions[,k] <- c(calculate.layer.contribution(conStruct.results=conStruct.results[[1]],
                                                              data.block=data.block,
                                                              layer.order=tmp.order),
                                 rep(0,nm-k))
    tmp <- conStruct.results[[1]]$MAP$admix.proportions[,tmp.order]
  }
  row.names(layer.contributions) <- paste0("Layer_",1:nm)
  return(layer.contributions)
}


layer.contributions_TRUE <- lc.calculations(TRUE, 6)

pdf("conStruct_output/layer_contrib.pdf")
barplot(layer.contributions_TRUE,
        col=c("blue", "red", "goldenrod1", "forestgreen", "darkorchid1", "grey"),
        xlab="",
        ylab="layer contributions_TRUE",
        names.arg=paste0("K=",1:6))
dev.off()


# Cross validation analysis.
# this takes a while to run, it is essentially running each run multiple times.

my.xvals <- x.validation(train.prop = 0.9,
                         n.reps = 3,
                         K = 1:6,
                         freqs = cs$freq,
                         data.partitions = NULL,
                         geoDist = cs$dist,
                         coords = cs$lon_lat,
                         prefix = paste0("conStruct_output/cross_val/cross_val_",cs$prefix),
                         n.iter = 10000,
			 n.chains=2,
                         make.figs = TRUE,
                         save.files = TRUE)

	
sp.results <- as.matrix(
  read.table(paste0("conStruct_output/cross_val/cross_val_", cs$prefix, "_sp_xval_results.txt"), 
             header = TRUE,
             stringsAsFactors = FALSE)
)
nsp.results <- as.matrix(
  read.table(paste0("conStruct_output/cross_val/cross_val_", cs$prefix, "_nsp_xval_results.txt"),
             header = TRUE,
             stringsAsFactors = FALSE)
)

sp.CIs <- apply(sp.results,1,function(x){mean(x) + c(-1.96,1.96) * sd(x)/length(x)})
nsp.CIs <- apply(nsp.results,1,function(x){mean(x) + c(-1.96,1.96) * sd(x)/length(x)})

pdf("conStruct_output/cross_val/rowMeans.sp.results.pdf")

plot(rowMeans(sp.results),
     pch=19,col="blue",
     ylab="predictive accuracy",xlab="values of K",
     ylim=range(sp.results,nsp.results),
     main="cross-validation results")
points(rowMeans(nsp.results),col="green",pch=19)
segments(x0 = 1:nrow(sp.results),
         y0 = sp.CIs[1,],
         x1 = 1:nrow(sp.results),
         y1 = sp.CIs[2,],
         col = "blue",lwd=2)
segments(x0 = 1:nrow(nsp.results),
         y0 = nsp.CIs[1,],
         x1 = 1:nrow(nsp.results),
         y1 = nsp.CIs[2,],
         col = "green",lwd=2)

dev.off()


################# Running LEA & SNMF 
docker run --rm -it -v /home/karina/mqgwas/parent_iter_2/construct_iter4/:/data karinaguo/pkg_test:RRwf2_v23 R

library(LEA)
library(RRtools)
load("data/data/VCFData_wmeta.Rdata")


data$encoding = "altcount"
data$treatment = "NA"
dataset = "NA"
species = "MelaleucaQuinquenervia"

basedir = "data/data/lea_output/"
dir.create(basedir)

# Manually running dart2lea from RRtools
# dart2lea(dart_data, basedir, species, dataset, meta_data = FALSE)

lf_gt <- data$gt
lf_gt[is.na(lf_gt)] <- 9
treatment <- data$treatment

dir <- paste(basedir, species, sep = "")
if (!dir.exists(dir)) { cat("  Directory: ", dir, " does not exist and is being created. \n"); dir.create(dir) }

dir <- paste(basedir, species, "/popgen", sep = "")
if (!dir.exists(dir)) { cat("  Directory: ", dir, " does not exist and is being created. \n"); dir.create(dir) }

dir <- paste(basedir, species, "/popgen/", treatment, sep = "")
if (!dir.exists(dir)) { cat("  Directory: ", dir, " does not exist and is being created. \n"); dir.create(dir) }

lea_dir <- paste(basedir, species, "/popgen/", treatment, "/lea", sep = "")
if (!dir.exists(lea_dir)) { cat("  Directory: ", lea_dir, " does not exist and is being created. \n"); dir.create(lea_dir) }
lea_file <- paste(lea_dir, "/", species, "_", dataset, ".lfmm", sep = "")
write.table(lf_gt, file = lea_file, sep = " ", quote = FALSE, row.names = FALSE, col.names = FALSE)

lea_fil <- lea_file

### Continuing with RR_gdm.R
lea_file_genotype <- read.lfmm(lea_fil)
write.geno(lea_file_genotype, paste0(lea_dir,"/",species,"_",dataset,"_genotype.geno", sep = ""))
snmf_project <- snmf(paste0(lea_dir,"/",species,"_",dataset,"_genotype.geno", sep = ""), K=1:6, entropy = TRUE, repetitions = 9, project = "new")

lea_plot   <- paste(basedir,species,"/popgen/",treatment,"/lea/K_ce.pdf", sep="")
pdf(file=lea_plot)
tryCatch(plot(snmf_project, lwd = 5, col = "red", pch=1), error = function(err) print("Lea plot failed, try sourcing code externally"))
dev.off()

basedir = "data/data/lea_output"
suppressWarnings({
  for (K in 2:6) {
    
    ce <- cross.entropy(snmf_project, K = K)
    Rbest <- which.min(ce)
    
    qmatrix <- Q(snmf_project, K = K, run = Rbest)
    
    ind_Q_file <- file.path(basedir, species, "popgen", treatment, "lea", paste0(species, "_", dataset, "_K", K, "_indQ.txt"))
    
    vals <- cbind(data$meta$site, data$meta$long, data$meta$lat, qmatrix)
    colnames(vals)[1:3] <- c("site", "long", "lat")
    rownames(vals) <- rownames(data$gt)
    write.table(vals, ind_Q_file, quote = FALSE, col.names = TRUE, row.names = TRUE, sep = ",")
    
    pop = data$meta$analyses$RR1
    
    pop_Q_file <- file.path(basedir, species, "popgen", treatment, "lea", paste0(species, "_", dataset, "_K", K, "_popQ.txt"))
    pop_Q_fig <- file.path(basedir, species, "popgen", treatment, "lea", paste0(species, "_", dataset, "_K", K, "_popQ.pdf"))
    
    pop_Q_vals <- matrix(NA, nrow = length(unique(pop)), ncol = K)
    pop_ll <- matrix(NA, nrow = length(unique(pop)), ncol = 2)
    
    rownames(pop_Q_vals) <- rownames(pop_ll) <- unique(pop)
    
    for (p in unique(pop)) {
      qpop <- qmatrix[pop == p, ]
      if (length(which(pop == p)) == 1) {
        pop_Q_vals[p, ] = qpop
        pop_ll[p, ] = c(data$meta$long[pop == p], data$meta$lat[pop == p])
      } else {
        pop_Q_vals[p, ] = colMeans(qpop)
        pop_ll[p, ] = colMeans(cbind(data$meta$long, data$meta$lat)[pop == p, ])
      }
    }
    
    pop_vals <- cbind(unique(pop), pop_ll, pop_Q_vals)
    write.table(pop_vals, pop_Q_file, quote = FALSE, sep = ",")
    
    require(mapplots)
    require(maps)
    require(mapdata)
    
    tmp_pop_ll <- na.omit(pop_ll)
    tmp_pop_Q_vals <- subset(pop_Q_vals, rownames(pop_Q_vals) %in% rownames(tmp_pop_ll))
    
    pdf(file = pop_Q_fig)
    plot(tmp_pop_ll[, 1:2], xlab = "Longitude", ylab = "Latitude", type = "n")
    map(add = TRUE, col = "grey90", fill = TRUE)
    
    cols <- c("red", "blue", "yellow", "green", "gray", "orange", "violet", "lightgreen")[1:K]
    for (i in 1:nrow(tmp_pop_Q_vals)) {
      add.pie(z = tmp_pop_Q_vals[i, ], x = tmp_pop_ll[i, 1], y = tmp_pop_ll[i, 2], labels = "", col = cols, radius = 0.15, alpha = 0.5)
    }
    dev.off()
  }
})


